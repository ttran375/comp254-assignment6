{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Assignment #6 – Using Maps and Hash Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If your first name starts with a letter from A-J inclusively:**\n",
    "\n",
    "Our `AbstractHashMap` class maintains a load factor l ≤ 0.5. Reimplement\n",
    "that class to allow the user to specify the maximum load, and adjust the\n",
    "concrete subclasses accordingly.\n",
    "\n",
    "Perform experiments on our `ProbeHashMap` classes to measure its\n",
    "efficiency using random key sets and varying limits on the load factor.\n",
    "Do you think `ProbeHashMap` is better or `ChainHashMap`? When and how?\n",
    "\n",
    "**Hint** The load factor can be controlled from within the abstract\n",
    "class, but there must be means for setting the parameter (either through\n",
    "the constructor, or a new method).\n",
    "\n",
    "Write a Java/Python application to test your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Factor | Insert Time (s) | Retrieval Time (s)\n",
      "-----------------------------------------------\n",
      "0.10       | 0.013463      | 0.002127\n",
      "0.20       | 0.007283      | 0.002745\n",
      "0.30       | 0.007456      | 0.001964\n",
      "0.40       | 0.005632      | 0.002085\n",
      "0.50       | 0.006297      | 0.004177\n",
      "0.60       | 0.009743      | 0.002105\n",
      "0.70       | 0.016293      | 0.003860\n",
      "0.80       | 0.006396      | 0.003594\n",
      "0.90       | 0.007616      | 0.003833\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from random import randrange\n",
    "\n",
    "from probe_hash_map import ProbeHashMap\n",
    "\n",
    "\n",
    "def test_efficiency(max_load_factors, num_items):\n",
    "    results = {}\n",
    "    for max_load in max_load_factors:\n",
    "        hashmap = ProbeHashMap(max_load=max_load)\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Insert random key-value pairs\n",
    "        for _ in range(num_items):\n",
    "            key = randrange(10 * num_items)\n",
    "            value = randrange(10 * num_items)\n",
    "            hashmap[key] = value\n",
    "\n",
    "        # Measure insertion time\n",
    "        insert_time = time.time() - start_time\n",
    "\n",
    "        # Measure retrieval time\n",
    "        start_time = time.time()\n",
    "        for _ in range(num_items):\n",
    "            key = randrange(10 * num_items)\n",
    "            try:\n",
    "                _ = hashmap[key]\n",
    "            except KeyError:\n",
    "                pass\n",
    "        retrieval_time = time.time() - start_time\n",
    "\n",
    "        results[max_load] = (insert_time, retrieval_time)\n",
    "    return results\n",
    "\n",
    "\n",
    "def main():\n",
    "    max_load_factors = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    num_items = 1000\n",
    "    results = test_efficiency(max_load_factors, num_items)\n",
    "\n",
    "    print(\"Load Factor | Insert Time (s) | Retrieval Time (s)\")\n",
    "    print(\"-----------------------------------------------\")\n",
    "    for max_load, (insert_time, retrieval_time) in results.items():\n",
    "        print(f\"{max_load:.2f}       | {insert_time:.6f}      | {retrieval_time:.6f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If your first name starts with a letter from K-Z inclusively:**\n",
    "\n",
    "Our `AbstractHashMap` class maintains a load factor l ≤ 0.5. Reimplement\n",
    "that class to allow the user to specify the maximum load, and adjust the\n",
    "concrete subclasses accordingly.\n",
    "\n",
    "Perform experiments on our `ChainHashMap` classes to measure its\n",
    "efficiency using random key sets and varying limits on the load factor.\n",
    "Do you think `ProbeHashMap` is better or `ChainHashMap`? When and how?\n",
    "\n",
    "**Hint** The load factor can be controlled from within the abstract\n",
    "class, but there must be means for setting the parameter (either through\n",
    "the constructor, or a new method).\n",
    "\n",
    "Write a Java/Python application to test your solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Factor | Insert Time (s) | Retrieval Time (s)\n",
      "-----------------------------------------------\n",
      "0.10       | 0.007558      | 0.001886\n",
      "0.20       | 0.009452      | 0.001878\n",
      "0.30       | 0.010275      | 0.003392\n",
      "0.40       | 0.007042      | 0.001985\n",
      "0.50       | 0.010714      | 0.003715\n",
      "0.60       | 0.008236      | 0.001914\n",
      "0.70       | 0.032945      | 0.001930\n",
      "0.80       | 0.007297      | 0.002882\n",
      "0.90       | 0.006703      | 0.001991\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from random import randint\n",
    "\n",
    "from chain_hash_map import ChainHashMap\n",
    "\n",
    "\n",
    "def test_efficiency(max_load_factors, num_items):\n",
    "    results = {}\n",
    "    for max_load in max_load_factors:\n",
    "        hashmap = ChainHashMap(max_load=max_load)\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Insert random key-value pairs\n",
    "        for _ in range(num_items):\n",
    "            key = randint(0, 10 * num_items)\n",
    "            value = randint(0, 10 * num_items)\n",
    "            hashmap[key] = value\n",
    "\n",
    "        # Measure insertion time\n",
    "        insert_time = time.time() - start_time\n",
    "\n",
    "        # Measure retrieval time\n",
    "        start_time = time.time()\n",
    "        for _ in range(num_items):\n",
    "            key = randint(0, 10 * num_items)\n",
    "            try:\n",
    "                _ = hashmap[key]\n",
    "            except KeyError:\n",
    "                pass\n",
    "        retrieval_time = time.time() - start_time\n",
    "\n",
    "        results[max_load] = (insert_time, retrieval_time)\n",
    "    return results\n",
    "\n",
    "\n",
    "def main():\n",
    "    max_load_factors = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    num_items = 1000\n",
    "    results = test_efficiency(max_load_factors, num_items)\n",
    "\n",
    "    print(\"Load Factor | Insert Time (s) | Retrieval Time (s)\")\n",
    "    print(\"-----------------------------------------------\")\n",
    "    for max_load, (insert_time, retrieval_time) in results.items():\n",
    "        print(f\"{max_load:.2f}       | {insert_time:.6f}      | {retrieval_time:.6f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We use **ProbeHashMap** when we expect fewer collisions and want better performance with a lower load factor (≤ 0.5).\n",
    "- We use **ChainHashMap** when we need consistent performance even with a higher load factor (> 0.5)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

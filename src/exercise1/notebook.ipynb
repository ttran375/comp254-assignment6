{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Assignment #6 – Using Maps and Hash Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If your first name starts with a letter from A-J inclusively:**\n",
    "\n",
    "Our `AbstractHashMap` class maintains a load factor l ≤ 0.5. Reimplement\n",
    "that class to allow the user to specify the maximum load, and adjust the\n",
    "concrete subclasses accordingly.\n",
    "\n",
    "Perform experiments on our `ProbeHashMap` classes to measure its\n",
    "efficiency using random key sets and varying limits on the load factor.\n",
    "Do you think `ProbeHashMap` is better or `ChainHashMap`? When and how?\n",
    "\n",
    "**Hint** The load factor can be controlled from within the abstract\n",
    "class, but there must be means for setting the parameter (either through\n",
    "the constructor, or a new method).\n",
    "\n",
    "Write a Java/Python application to test your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Factor | Insert Time (s) | Retrieval Time (s)\n",
      "-----------------------------------------------\n",
      "0.10       | 0.009629      | 0.002059\n",
      "0.20       | 0.007827      | 0.001971\n",
      "0.30       | 0.014478      | 0.002105\n",
      "0.40       | 0.005704      | 0.002324\n",
      "0.50       | 0.007345      | 0.002993\n",
      "0.60       | 0.007299      | 0.002178\n",
      "0.70       | 0.009514      | 0.002230\n",
      "0.80       | 0.006722      | 0.003325\n",
      "0.90       | 0.008202      | 0.004286\n"
     ]
    }
   ],
   "source": [
    "from random import randrange\n",
    "from collections.abc import MutableMapping\n",
    "import time\n",
    "\n",
    "\n",
    "class MapBase(MutableMapping):\n",
    "    class _Item:\n",
    "        __slots__ = \"_key\", \"_value\"\n",
    "\n",
    "        def __init__(self, k, v):\n",
    "            self._key = k\n",
    "            self._value = v\n",
    "\n",
    "        def __eq__(self, other):\n",
    "            return self._key == other._key\n",
    "\n",
    "        def __ne__(self, other):\n",
    "            return not (self == other)\n",
    "\n",
    "        def __lt__(self, other):\n",
    "            return self._key < other._key\n",
    "\n",
    "\n",
    "class HashMapBase(MapBase):\n",
    "    def __init__(self, cap=11, p=109345121, max_load=0.5):\n",
    "        self._table = cap * [None]\n",
    "        self._n = 0\n",
    "        self._prime = p\n",
    "        self._scale = 1 + randrange(p - 1)\n",
    "        self._shift = randrange(p)\n",
    "        self._max_load = max_load\n",
    "\n",
    "    def _hash_function(self, k):\n",
    "        return (hash(k) * self._scale + self._shift) % self._prime % len(self._table)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._n\n",
    "\n",
    "    def __getitem__(self, k):\n",
    "        j = self._hash_function(k)\n",
    "        return self._bucket_getitem(j, k)\n",
    "\n",
    "    def __setitem__(self, k, v):\n",
    "        j = self._hash_function(k)\n",
    "        self._bucket_setitem(j, k, v)\n",
    "        if self._n > len(self._table) * self._max_load:\n",
    "            self._resize(2 * len(self._table) - 1)\n",
    "\n",
    "    def __delitem__(self, k):\n",
    "        j = self._hash_function(k)\n",
    "        self._bucket_delitem(j, k)\n",
    "        self._n -= 1\n",
    "\n",
    "    def _resize(self, c):\n",
    "        old = list(self.items())\n",
    "        self._table = c * [None]\n",
    "        self._n = 0\n",
    "        for k, v in old:\n",
    "            self[k] = v\n",
    "\n",
    "\n",
    "class ProbeHashMap(HashMapBase):\n",
    "    _AVAIL = object()\n",
    "\n",
    "    def _is_available(self, j):\n",
    "        return self._table[j] is None or self._table[j] is ProbeHashMap._AVAIL\n",
    "\n",
    "    def _find_slot(self, j, k):\n",
    "        firstAvail = None\n",
    "        while True:\n",
    "            if self._is_available(j):\n",
    "                if firstAvail is None:\n",
    "                    firstAvail = j\n",
    "                if self._table[j] is None:\n",
    "                    return (False, firstAvail)\n",
    "            elif k == self._table[j]._key:\n",
    "                return (True, j)\n",
    "            j = (j + 1) % len(self._table)\n",
    "\n",
    "    def _bucket_getitem(self, j, k):\n",
    "        found, s = self._find_slot(j, k)\n",
    "        if not found:\n",
    "            raise KeyError(\"Key Error: \" + repr(k))\n",
    "        return self._table[s]._value\n",
    "\n",
    "    def _bucket_setitem(self, j, k, v):\n",
    "        found, s = self._find_slot(j, k)\n",
    "        if not found:\n",
    "            self._table[s] = self._Item(k, v)\n",
    "            self._n += 1\n",
    "        else:\n",
    "            self._table[s]._value = v\n",
    "\n",
    "    def _bucket_delitem(self, j, k):\n",
    "        found, s = self._find_slot(j, k)\n",
    "        if not found:\n",
    "            raise KeyError(\"Key Error: \" + repr(k))\n",
    "        self._table[s] = ProbeHashMap._AVAIL\n",
    "\n",
    "    def __iter__(self):\n",
    "        for j in range(len(self._table)):\n",
    "            if not self._is_available(j):\n",
    "                yield self._table[j]._key\n",
    "\n",
    "\n",
    "# Testing the implementation\n",
    "\n",
    "\n",
    "def test_efficiency(max_load_factors, num_items):\n",
    "    results = {}\n",
    "    for max_load in max_load_factors:\n",
    "        hashmap = ProbeHashMap(max_load=max_load)\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Insert random key-value pairs\n",
    "        for _ in range(num_items):\n",
    "            key = randrange(10 * num_items)\n",
    "            value = randrange(10 * num_items)\n",
    "            hashmap[key] = value\n",
    "\n",
    "        # Measure insertion time\n",
    "        insert_time = time.time() - start_time\n",
    "\n",
    "        # Measure retrieval time\n",
    "        start_time = time.time()\n",
    "        for _ in range(num_items):\n",
    "            key = randrange(10 * num_items)\n",
    "            try:\n",
    "                _ = hashmap[key]\n",
    "            except KeyError:\n",
    "                pass\n",
    "        retrieval_time = time.time() - start_time\n",
    "\n",
    "        results[max_load] = (insert_time, retrieval_time)\n",
    "    return results\n",
    "\n",
    "\n",
    "def main():\n",
    "    max_load_factors = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    num_items = 1000\n",
    "    results = test_efficiency(max_load_factors, num_items)\n",
    "\n",
    "    print(\"Load Factor | Insert Time (s) | Retrieval Time (s)\")\n",
    "    print(\"-----------------------------------------------\")\n",
    "    for max_load, (insert_time, retrieval_time) in results.items():\n",
    "        print(f\"{max_load:.2f}       | {insert_time:.6f}      | {retrieval_time:.6f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If your first name starts with a letter from K-Z inclusively:**\n",
    "\n",
    "Our `AbstractHashMap` class maintains a load factor l ≤ 0.5. Reimplement\n",
    "that class to allow the user to specify the maximum load, and adjust the\n",
    "concrete subclasses accordingly.\n",
    "\n",
    "Perform experiments on our `ChainHashMap` classes to measure its\n",
    "efficiency using random key sets and varying limits on the load factor.\n",
    "Do you think `ProbeHashMap` is better or `ChainHashMap`? When and how?\n",
    "\n",
    "**Hint** The load factor can be controlled from within the abstract\n",
    "class, but there must be means for setting the parameter (either through\n",
    "the constructor, or a new method).\n",
    "\n",
    "Write a Java/Python application to test your solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Factor | Insert Time (s) | Retrieval Time (s)\n",
      "-----------------------------------------------\n",
      "0.10       | 0.009829      | 0.002911\n",
      "0.20       | 0.009021      | 0.003078\n",
      "0.30       | 0.011263      | 0.004108\n",
      "0.40       | 0.009771      | 0.002659\n",
      "0.50       | 0.030274      | 0.001943\n",
      "0.60       | 0.010366      | 0.001941\n",
      "0.70       | 0.008969      | 0.001913\n",
      "0.80       | 0.006477      | 0.002210\n",
      "0.90       | 0.009431      | 0.002065\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from collections.abc import MutableMapping\n",
    "from random import randint, randrange\n",
    "\n",
    "\n",
    "class MapBase(MutableMapping):\n",
    "    class _Item:\n",
    "        __slots__ = \"_key\", \"_value\"\n",
    "\n",
    "        def __init__(self, k, v):\n",
    "            self._key = k\n",
    "            self._value = v\n",
    "\n",
    "        def __eq__(self, other):\n",
    "            return self._key == other._key\n",
    "\n",
    "        def __ne__(self, other):\n",
    "            return not (self == other)\n",
    "\n",
    "        def __lt__(self, other):\n",
    "            return self._key < other._key\n",
    "\n",
    "\n",
    "class HashMapBase(MapBase):\n",
    "    def __init__(self, cap=11, p=109345121, max_load=0.5):\n",
    "        self._table = cap * [None]\n",
    "        self._n = 0\n",
    "        self._prime = p\n",
    "        self._scale = 1 + randrange(p - 1)\n",
    "        self._shift = randrange(p)\n",
    "        self._max_load = max_load\n",
    "\n",
    "    def _hash_function(self, k):\n",
    "        return (hash(k) * self._scale + self._shift) % self._prime % len(self._table)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._n\n",
    "\n",
    "    def __getitem__(self, k):\n",
    "        j = self._hash_function(k)\n",
    "        return self._bucket_getitem(j, k)\n",
    "\n",
    "    def __setitem__(self, k, v):\n",
    "        j = self._hash_function(k)\n",
    "        self._bucket_setitem(j, k, v)\n",
    "        if self._n > len(self._table) * self._max_load:\n",
    "            self._resize(2 * len(self._table) - 1)\n",
    "\n",
    "    def __delitem__(self, k):\n",
    "        j = self._hash_function(k)\n",
    "        self._bucket_delitem(j, k)\n",
    "        self._n -= 1\n",
    "\n",
    "    def _resize(self, c):\n",
    "        old = list(self.items())\n",
    "        self._table = c * [None]\n",
    "        self._n = 0\n",
    "        for k, v in old:\n",
    "            self[k] = v\n",
    "\n",
    "\n",
    "class UnsortedTableMap(MapBase):\n",
    "    def __init__(self):\n",
    "        self._table = []\n",
    "\n",
    "    def __getitem__(self, k):\n",
    "        for item in self._table:\n",
    "            if k == item._key:\n",
    "                return item._value\n",
    "        raise KeyError(\"Key Error: \" + repr(k))\n",
    "\n",
    "    def __setitem__(self, k, v):\n",
    "        for item in self._table:\n",
    "            if k == item._key:\n",
    "                item._value = v\n",
    "                return\n",
    "        self._table.append(self._Item(k, v))\n",
    "\n",
    "    def __delitem__(self, k):\n",
    "        for j in range(len(self._table)):\n",
    "            if k == self._table[j]._key:\n",
    "                self._table.pop(j)\n",
    "                return\n",
    "        raise KeyError(\"Key Error: \" + repr(k))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._table)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for item in self._table:\n",
    "            yield item._key\n",
    "\n",
    "\n",
    "class ChainHashMap(HashMapBase):\n",
    "    def _bucket_getitem(self, j, k):\n",
    "        bucket = self._table[j]\n",
    "        if bucket is None:\n",
    "            raise KeyError(\"Key Error: \" + repr(k))\n",
    "        return bucket[k]\n",
    "\n",
    "    def _bucket_setitem(self, j, k, v):\n",
    "        if self._table[j] is None:\n",
    "            self._table[j] = UnsortedTableMap()\n",
    "        oldsize = len(self._table[j])\n",
    "        self._table[j][k] = v\n",
    "        if len(self._table[j]) > oldsize:\n",
    "            self._n += 1\n",
    "\n",
    "    def _bucket_delitem(self, j, k):\n",
    "        bucket = self._table[j]\n",
    "        if bucket is None:\n",
    "            raise KeyError(\"Key Error: \" + repr(k))\n",
    "        del bucket[k]\n",
    "\n",
    "    def __iter__(self):\n",
    "        for bucket in self._table:\n",
    "            if bucket is not None:\n",
    "                for key in bucket:\n",
    "                    yield key\n",
    "\n",
    "\n",
    "def test_efficiency(max_load_factors, num_items):\n",
    "    results = {}\n",
    "    for max_load in max_load_factors:\n",
    "        hashmap = ChainHashMap(max_load=max_load)\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Insert random key-value pairs\n",
    "        for _ in range(num_items):\n",
    "            key = randint(0, 10 * num_items)\n",
    "            value = randint(0, 10 * num_items)\n",
    "            hashmap[key] = value\n",
    "\n",
    "        # Measure insertion time\n",
    "        insert_time = time.time() - start_time\n",
    "\n",
    "        # Measure retrieval time\n",
    "        start_time = time.time()\n",
    "        for _ in range(num_items):\n",
    "            key = randint(0, 10 * num_items)\n",
    "            try:\n",
    "                _ = hashmap[key]\n",
    "            except KeyError:\n",
    "                pass\n",
    "        retrieval_time = time.time() - start_time\n",
    "\n",
    "        results[max_load] = (insert_time, retrieval_time)\n",
    "    return results\n",
    "\n",
    "\n",
    "def main():\n",
    "    max_load_factors = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    num_items = 1000\n",
    "    results = test_efficiency(max_load_factors, num_items)\n",
    "\n",
    "    print(\"Load Factor | Insert Time (s) | Retrieval Time (s)\")\n",
    "    print(\"-----------------------------------------------\")\n",
    "    for max_load, (insert_time, retrieval_time) in results.items():\n",
    "        print(f\"{max_load:.2f}       | {insert_time:.6f}      | {retrieval_time:.6f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **When to Use ProbeHashMap**:\n",
    "  - When the expected load factor is low (≤ 0.5).\n",
    "  - When memory efficiency is a priority.\n",
    "  - When cache performance is critical.\n",
    "\n",
    "- **When to Use ChainHashMap**:\n",
    "  - When the load factor is expected to be high (> 0.5).\n",
    "  - When uniform performance is needed even with higher load factors.\n",
    "  - When memory usage is less of a concern compared to consistent performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
